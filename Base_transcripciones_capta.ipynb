{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtYZWoHvP72oDspYF5CRob",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wikimx/Capstone-Delivery/blob/master/Base_transcripciones_capta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x1dVtA5IEYn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import re\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBQrbstqPbbg",
        "outputId": "86bda5a0-0ccc-4c05-cc50-fd30d64e07be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_transcription(file_name):\n",
        "    \"\"\"\n",
        "    Process a transcription file to extract structured data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_name, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(\"The specified file was not found.\")\n",
        "\n",
        "    # Extract metadata from the file name\n",
        "    match = re.match(r\"Grupo (.+) Plaza (.+) Edades (.+) NSE (.+)\\.txt\", file_name.split('/')[-1])\n",
        "    if not match:\n",
        "        raise ValueError(\"File name format is incorrect. Expected format: 'Grupo [Name] Plaza [Name] Edades [Range] NSE [Value].txt'\")\n",
        "\n",
        "    Grupo, Plaza, Edades, NSE = match.groups()\n",
        "\n",
        "    data = []\n",
        "    # Adjusted pattern to handle both mm:ss and hh:mm:ss\n",
        "    pattern = r\"^(\\d{1,2}:\\d{2}(?::\\d{2})?)\\s+([^:]+):\\s+(.+)\"\n",
        "\n",
        "    for line in lines:\n",
        "        match = re.match(pattern, line)\n",
        "        if match:\n",
        "            Tiempo, Nombre, participation = match.groups()\n",
        "\n",
        "            # Normalize mm:ss to hh:mm:ss\n",
        "            if len(Tiempo.split(':')) == 2:\n",
        "                Tiempo = f\"00:{Tiempo}\"\n",
        "\n",
        "            data.append({\n",
        "                \"Grupo\": Grupo,\n",
        "                'Tiempo': Tiempo,\n",
        "                'Nombre': Nombre,\n",
        "                'Participación': participation.strip(),\n",
        "                'Plaza': Plaza,\n",
        "                'NSE': NSE,\n",
        "                'Edades': Edades\n",
        "            })\n",
        "\n",
        "    if not data:\n",
        "        raise ValueError(\"No valid data extracted from the transcription file.\")\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# List of file names\n",
        "file_names = [\n",
        "    \"/content/Grupo SG1 Plaza Jal Edades 18 a 25 años NSE C-D+.txt\",\n",
        "    \"/content/Grupo SG2 Plaza Jal Edades 35 a 55 años NSE C-D+.txt\",\n",
        "    \"/content/Grupo SG3 Plaza Jal Edades 35 a 55 años NSE C+B.txt\",\n",
        "    \"/content/Grupo SG4 Plaza NL Edades 18 a 25 años NSE C-D+.txt\",\n",
        "    \"/content/Grupo SG5 Plaza NL Edades 35 a 55 años NSE C-D+.txt\",\n",
        "    \"/content/Grupo SG6 Plaza NL Edades 35 a 55 años NSE C+B.txt\",\n",
        "    \"/content/Grupo SG7 Plaza CDMX Edades 18 a 25 años NSE C-D+.txt\",\n",
        "    \"/content/Grupo SG8 Plaza CDMX Edades 35 a 55 años NSE C-D+.txt\",\n",
        "    \"/content/Grupo SG9 Plaza CDMX Edades 18 a 27 años NSE C+B.txt\",\n",
        "\n",
        "]\n",
        "\n",
        "all_dataframes = []\n",
        "\n",
        "try:\n",
        "    for file_name in file_names:\n",
        "        # Process each transcription file\n",
        "        df = process_transcription(file_name)\n",
        "        all_dataframes.append(df)\n",
        "\n",
        "    # Combine all dataframes into one\n",
        "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "\n",
        "    # Display the first rows of the combined DataFrame\n",
        "    print(combined_df.head())\n",
        "\n",
        "    # Save the combined DataFrame to a CSV file\n",
        "    combined_df.to_csv(\"combined_transcriptions.csv\", index=False, encoding='utf-8')\n",
        "    print(\"All files processed and saved successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "# List of known moderators\n",
        "moderators = [\"Daniela RK\", \"Yvone Carrillo\",  \"Yvon Carrillo\", \"Dan Cortés\", \"Carlos Villanueva Avilez\", \"Karime Galicia\", \"Mario Juárez\", \"Natalia Rodríguez\", \"Diego De Alba Montes\", \"Daniel Behn\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD4wGwu8NQAR",
        "outputId": "617917c3-adbe-44d4-85df-526725f8b722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Grupo    Tiempo                    Nombre  \\\n",
            "0   SG1  00:00:06            Karime Galicia   \n",
            "1   SG1  00:07:09  myriam martinez baltazar   \n",
            "2   SG1  00:07:09            Karime Galicia   \n",
            "3   SG1  00:07:11  myriam martinez baltazar   \n",
            "4   SG1  00:07:12            Karime Galicia   \n",
            "\n",
            "                                       Participación Plaza   NSE        Edades  \n",
            "0                 Hola Miri cómo estás Buenas tardes   Jal  C-D+  18 a 25 años  \n",
            "1                                 Hola buenas tardes   Jal  C-D+  18 a 25 años  \n",
            "2                                    Hola cómo estás   Jal  C-D+  18 a 25 años  \n",
            "3                                       Bien y usted   Jal  C-D+  18 a 25 años  \n",
            "4  Bien también Muchas gracias, muchas muchas gra...   Jal  C-D+  18 a 25 años  \n",
            "All files processed and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def anonymize_and_flag(df):\n",
        "    \"\"\"\n",
        "    Add a column to flag if the person is a Moderador or Participante,\n",
        "    \"\"\"\n",
        "    # Create a column to flag if the row corresponds to a Moderator\n",
        "    df['Rol'] = df['Nombre'].apply(lambda x: 'Moderador' if x in moderators else 'Participante')\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load the previously saved DataFrame\n",
        "combined_df = pd.read_csv(\"/content/combined_transcriptions.csv\")\n",
        "\n",
        "# Process the DataFrame to flag roles and anonymize participant names\n",
        "processed_df = anonymize_and_flag(combined_df)\n",
        "\n",
        "# Save the processed DataFrame to a new CSV file\n",
        "processed_df.to_csv(\"Base de datos.csv\", index=False, encoding='utf-8')\n",
        "\n",
        "print(\"Roles de Moderadores y participantes agregados\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkfqYiCBN8hQ",
        "outputId": "7d15df9a-6ae1-43ff-abb1-b3654494b643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Roles de Moderadores y participantes agregados\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf3eCjE-LLPH",
        "outputId": "92051d92-c719-4261-a2d0-4d3f83217faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Participation text cleaned and saved successfully.\n"
          ]
        }
      ],
      "source": [
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # This line was added\n",
        "\n",
        "def clean_text(participación):\n",
        "    \"\"\"\n",
        "    Clean and preprocess the participation text.\n",
        "    \"\"\"\n",
        "    # Remove non-alphanumeric characters, except spaces\n",
        "    text = re.sub(r'[^\\w\\s]', '', participación)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text, language='spanish')\n",
        "    # Join tokens back into a string without removing stopwords\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Apply text cleaning to the participation column without removing stopwords.\n",
        "    \"\"\"\n",
        "    df['Participación limpia'] = df['Participación'].apply(clean_text)\n",
        "    return df\n",
        "\n",
        "# Load the previously processed DataFrame\n",
        "processed_df = pd.read_csv(\"/content/Base de datos.csv\")\n",
        "\n",
        "# Clean the participation column\n",
        "cleaned_df = preprocess_data(processed_df)\n",
        "\n",
        "# Save the cleaned DataFrame to a new CSV file\n",
        "cleaned_df.to_csv(\"Base de datos 2.csv\", index=False, encoding='utf-8')\n",
        "\n",
        "print(\"Participation text cleaned and saved successfully.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coatza"
      ],
      "metadata": {
        "id": "wC6La6Oc6PYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final adjusted thematic categories in English (excluding proper nouns)\n",
        "thematic_categories = {\n",
        "    \"Orgullo\": [\"orgullo\", \"orgulloso\", \"identidad\"],\n",
        "    \"Problemáticas\": [\"corrupción\", \"impunidad\", \"transa\", \"mordida\", \"problema\", \"violencia\", \"inseguridad\", \"narco\", \"robo\", \"asalto\", \"trabajo\", \"tráfico\", \"vialidades\"],\n",
        "    \"Elecciones\": [\"elección\", \"candidato\", \"candidata\", \"fraude\", \"optimismo\", \"desilusión\", \"votación\", \"legitimidad\", \"sentimiento\", \"emoción\", \"elecciones\", \"voto\", \"casillas\"],\n",
        "    \"Morena\": [\"obrador\", \"amlo\", \"morena\", \"moreno\", \"guinda\", \"andres manuel lopez\"],\n",
        "    \"Movimiento Ciudadano\": [\"movimiento ciudadano\", \"naranja\", \"canción\"],\n",
        "    \"PRIAN\": [\"pri\", \"anaya\", \"pan\", \"prian\", \"xochitl\"],\n",
        "}\n",
        "\n",
        "# Propagation categories (Only for Moderators, but propagates to Participants and Moderators)\n",
        "propagation_categories = {\n",
        "    \"Percepción pública del país y problemas sociales\": [\"como te hace sentir\", \"tres principales problemas del país\", \"hablemos de el pais\", \"hablemos del pais\", \"vamos a empezar con algo emocional\"],\n",
        "    \"Evaluación de Claudia Sheinbaum\": [\"hablemos de shein\", \"hablemos de sheinbaum\", \"hablemos de claudia\", \"como ven a la presidenta\", \"cómo ven a la presidenta\", \"presidenta\"],\n",
        "    \"Bloques específicos regionales\": [\"dicen de su estado\", \"nivel municipal\", \"nivel estatal\", \"\" \"como ven el estado\", \"hablemos de cdmx\", \"hablemos de cedeeme equis\", \"chablemos de nuevo león\", \"hablemos de nuevo leon\", \"hablemos de jalisco\", \"hablemos de baja california\", \" hablemos de guanajuato\", \"hablemos de yucatan\", \"hablemos de yucatán\"],\n",
        "    \"Morena\": [\"un apodo a morena\", \"hablemos de morena\", \"hoy de morena\"],\n",
        "    \"Movimiento Ciudadano\": [\"hablemos de movimiento\"],\n",
        "    \"PRI\": [\"un apodo al pri\", \"Si el pri fuera\", \"hablemos de el pri\", \"hablemos del pri\"],\n",
        "    \"PAN\": [\"un apodo al pan\", \"apodo le pondrías al pan\", \"hablemos de el pan\", \"hablemos del pan\"],\n",
        "\n",
        "}\n",
        "\n",
        "# Function to classify participation into multiple themes\n",
        "def classify_multiple_thematic_categories(text, categories):\n",
        "    assigned_themes = set()\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()  # Normalize text to lowercase\n",
        "        for theme, keywords in categories.items():\n",
        "            for keyword in keywords:\n",
        "                if re.search(rf'\\b{keyword}\\b', text):\n",
        "                    assigned_themes.add(theme)\n",
        "    return \", \".join(assigned_themes) if assigned_themes else \"Sin Clasificar\"\n",
        "\n",
        "# Function to classify propagation categories (Only for Moderators)\n",
        "def classify_propagation_categories(text, categories):\n",
        "    assigned_themes = set()\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()  # Normalize text to lowercase\n",
        "        for theme, keywords in categories.items():\n",
        "            for keyword in keywords:\n",
        "                if re.search(rf'\\b{keyword}\\b', text):\n",
        "                    assigned_themes.add(theme)\n",
        "    return \", \".join(assigned_themes) if assigned_themes else \"Sin Clasificar\"\n",
        "\n",
        "# Apply thematic classification to both participants and moderators (No propagation)\n",
        "def classify_thematic_categories(group):\n",
        "    group['Categorias extra'] = group['Participación limpia'].apply(\n",
        "        lambda text: classify_multiple_thematic_categories(text, thematic_categories)\n",
        "    )\n",
        "    return group\n",
        "\n",
        "# Apply propagation classification only to moderators\n",
        "def classify_propagation(group):\n",
        "    group['Categorias bloque'] = group.apply(\n",
        "        lambda row: classify_propagation_categories(row['Participación limpia'], propagation_categories)\n",
        "        if row['Rol'] == 'Moderador' else \"Sin Clasificar\", axis=1\n",
        "    )\n",
        "    return group\n",
        "\n",
        "# Propagate moderator themes to all responses within the same group and plaza\n",
        "def propagate_moderator_themes(group):\n",
        "    current_theme = None\n",
        "    for index, row in group.iterrows():\n",
        "        if row['Categorias bloque'] != \"Sin Clasificar\":  # Moderator introduces a new theme\n",
        "            current_theme = row['Categorias bloque']\n",
        "        elif current_theme:  # Propagate to both Moderators and Participants\n",
        "            if row['Categorias bloque'] == \"Sin Clasificar\":\n",
        "                group.at[index, 'Categorias bloque'] = current_theme\n",
        "            else:\n",
        "                existing_themes = set(row['Categorias bloque'].split(\", \"))\n",
        "                new_themes = existing_themes.union(set(current_theme.split(\", \")))\n",
        "                group.at[index, 'Categorias bloque'] = \", \".join(new_themes)\n",
        "    return group\n",
        "\n",
        "# Load the cleaned transcriptions file\n",
        "data_path = \"/content/Base de datos 2.csv\"\n",
        "cleaned_df = pd.read_csv(data_path, encoding='utf-8')\n",
        "\n",
        "# Sort data chronologically within groups\n",
        "cleaned_df = cleaned_df.sort_values(by=['Grupo', 'Plaza', 'Tiempo'])\n",
        "\n",
        "# Apply thematic classification (for both Moderators and Participants)\n",
        "cleaned_df = cleaned_df.groupby(['Grupo', 'Plaza'], group_keys=False).apply(classify_thematic_categories)\n",
        "\n",
        "# Apply propagation classification (only for Moderators)\n",
        "cleaned_df = cleaned_df.groupby(['Grupo', 'Plaza'], group_keys=False).apply(classify_propagation)\n",
        "\n",
        "# Propagate propagation themes from Moderators to both Moderators and Participants\n",
        "cleaned_df = cleaned_df.groupby(['Grupo', 'Plaza'], group_keys=False).apply(propagate_moderator_themes)\n",
        "\n",
        "# Save the results to a new CSV file\n",
        "output_path = \"Base de datos final.csv\"\n",
        "cleaned_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"Multi-thematic classification with updated rules completed, saved to '{output_path}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTTQh-J4kZr_",
        "outputId": "596ba344-d4a7-4e09-8c2c-331850f177a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-39-2720870036.py:83: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  cleaned_df = cleaned_df.groupby(['Grupo', 'Plaza'], group_keys=False).apply(classify_thematic_categories)\n",
            "/tmp/ipython-input-39-2720870036.py:86: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  cleaned_df = cleaned_df.groupby(['Grupo', 'Plaza'], group_keys=False).apply(classify_propagation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-thematic classification with updated rules completed, saved to 'Base de datos final.csv'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-39-2720870036.py:89: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  cleaned_df = cleaned_df.groupby(['Grupo', 'Plaza'], group_keys=False).apply(propagate_moderator_themes)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veracruz"
      ],
      "metadata": {
        "id": "PugDJOIP6LHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final adjusted thematic categories in English (excluding proper nouns)\n",
        "thematic_categories = {\n",
        "    \"Orgullo\": [\"orgullo\", \"orgulloso\", \"identidad\"],\n",
        "    \"Problematicas\": [\"corrupción\", \"impunidad\", \"transa\", \"mordida\", \"problema\", \"violencia\", \"inseguridad\", \"narco\", \"robo\", \"asalto\", \"trabajo\", \"tráfico\", \"vialidades\"],\n",
        "    \"Elecciones\": [\"elección\", \"candidato\", \"candidata\", \"fraude\", \"optimismo\", \"desilusión\", \"votación\", \"legitimidad\", \"sentimiento\", \"emoción\", \"elecciones\", \"voto\", \"casillas\"],\n",
        "    \"Morena\": [\"obrador\", \"amlo\", \"morena\", \"moreno\", \"guinda\", \"andres manuel lopez\"],\n",
        "    \"Movimiento Ciudadano\": [\"movimiento ciudadano\", \"naranja\", \"canción\"],\n",
        "    \"PRIAN\": [\"pri\", \"anaya\", \"pan\", \"prian\", \"xochitl\"],\n",
        "    \"Maynez\": [\"maynes\", \"maynez\", \"maines\", \"mainez\"],\n",
        "    \"Belem Palmeros\": [\"belem\", \"belén\", \"palmeros\"],\n",
        "    \"Raul Zarrabal\": [\"raul\", \"raúl\", \"sarrabal\", \"zarrabal\"],\n",
        "}\n",
        "\n",
        "# Propagation categories (Only for Moderators, but propagates to Participants and Moderators)\n",
        "propagation_categories = {\n",
        "    \"Contexto estatal\": [\"contarme acerca de veracruz\", \"habláramos del estado de veracruz\",\"hablemos de su estado\", \"cómo ve al estado en general\", \"ven yo solo veo ahí como\", \"hablemos de contexto social\", \"hablemos del contexto\", \"vamos a empezar bastante general\"],\n",
        "    \"Contexto local\": [\"los tres principales problemas de xalapa\", \"hablemos de la gente de xalapa\", \"hablemos de su municipio\", \"en cuanto a su ciudad\", \"describirías a la gente de xalapa\"],\n",
        "    \"Panorama electoral\": [\"hablemos de el panorama electoral\", \"hablemos del panorama electoral\", \"hablemos de panorama electoral\",\"seguimos con el tema del panorama electoral\", \"seguimos con el panorama electoral\", \"seguimos con panorama electoral\"],\n",
        "    \"PRI\": [\"tres palabras para describir al pri \", \"hablemos del pri\", \"empezando con el pri\", \"hablando súper rápido del pri\"],\n",
        "    \"PAN\": [\"del pan qué me dicen\", \"hablemos del pan\",  \"tres palabras para describir al pan\", \"me cuenta el pan\"],\n",
        "    \"Morena\": [\" la cuestión de xalapa talina\", \"hablemos de morena\", \"tres palabras para describir a morena\", \"hablamos de morena\"],\n",
        "    \"Movimiento Ciudadano\": [\"tres palabras movimiento ciudadano\", \"hablar de movimiento ciudadano\", \"hablemos de movimiento ciudadano\",\"movimiento ciudadano tres palabras\", \"tres palabras para describir a movimiento\"],\n",
        "    \"Maynez\": [\"okay okay alguien sabe quién es él\", \"fue candidato presidencial\", \"jorge álvarez máynez\", \"alvarez\",\"desde diciembre es\", \"fue candidato a la presidencia a las elecciones de 2024\"],\n",
        "    \"yunes\": [\"hablemos de los yunes\", \"respecto los yunes\", \"acerca de los yunes\"],\n",
        "    \"Roman Moreno\": [\"joven empresario dueño\", \"precandidato para movimiento ciudadano\", \"ha apoyado campañas y gobiernos\"],\n",
        "    \"Maribel Ramírez\": [\"diputada local del pan\", \"comisión para la igualdad de género\", \"candidata por el pan para la alcaldía\"],\n",
        "    \"Silvio Lagos\": [\"silvio lagos fue secretario general\", \"director estatal de asuntos\", \"candidato por parte del pri\"],\n",
        "    \"Daniela Griego\": [\"ex directora general del instituto\", \"promotora de la Cuarta \", \"daniela griego\"],\n",
        "    \"Evaluacion de boleta\": [\"va a ganar las elecciones municipales\", \"quién creen que va a ganar\"],\n",
        "}\n",
        "\n",
        "# Function to classify participation into multiple themes\n",
        "def classify_multiple_thematic_categories(text, categories):\n",
        "    assigned_themes = set()\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()  # Normalize text to lowercase\n",
        "        for theme, keywords in categories.items():\n",
        "            for keyword in keywords:\n",
        "                if re.search(rf'\\b{keyword}\\b', text):\n",
        "                    assigned_themes.add(theme)\n",
        "    return \", \".join(assigned_themes) if assigned_themes else \"Sin Clasificar\"\n",
        "\n",
        "# Function to classify propagation categories (Only for Moderators)\n",
        "def classify_propagation_categories(text, categories):\n",
        "    assigned_themes = set()\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()  # Normalize text to lowercase\n",
        "        for theme, keywords in categories.items():\n",
        "            for keyword in keywords:\n",
        "                if re.search(rf'\\b{keyword}\\b', text):\n",
        "                    assigned_themes.add(theme)\n",
        "    return \", \".join(assigned_themes) if assigned_themes else \"Sin Clasificar\"\n",
        "\n",
        "# Apply thematic classification to both participants and moderators (No propagation)\n",
        "def classify_thematic_categories(group):\n",
        "    group['Categorias extra'] = group['Participación limpia'].apply(\n",
        "        lambda text: classify_multiple_thematic_categories(text, thematic_categories)\n",
        "    )\n",
        "    return group\n",
        "\n",
        "# Apply propagation classification only to moderators\n",
        "def classify_propagation(group):\n",
        "    group['Categorias bloque'] = group.apply(\n",
        "        lambda row: classify_propagation_categories(row['Participación limpia'], propagation_categories)\n",
        "        if row['Rol'] == 'Moderador' else \"Sin Clasificar\", axis=1\n",
        "    )\n",
        "    return group\n",
        "\n",
        "# Propagate moderator themes to all responses within the same group and plaza\n",
        "def propagate_moderator_themes(group):\n",
        "    current_theme = None\n",
        "    for index, row in group.iterrows():\n",
        "        if row['Categorias bloque'] != \"Sin Clasificar\":  # Moderator introduces a new theme\n",
        "            current_theme = row['Categorias bloque']\n",
        "        elif current_theme:  # Propagate to both Moderators and Participants\n",
        "            if row['Categorias bloque'] == \"Sin Clasificar\":\n",
        "                group.at[index, 'Categorias bloque'] = current_theme\n",
        "            else:\n",
        "                existing_themes = set(row['Categorias bloque'].split(\", \"))\n",
        "                new_themes = existing_themes.union(set(current_theme.split(\", \")))\n",
        "                group.at[index, 'Categorias bloque'] = \", \".join(new_themes)\n",
        "    return group\n",
        "\n",
        "# Load the cleaned transcriptions file\n",
        "data_path = \"/content/Base de datos 2.csv\"\n",
        "cleaned_df = pd.read_csv(data_path, encoding='utf-8')\n",
        "\n",
        "# Sort data chronologically within groups\n",
        "cleaned_df = cleaned_df.sort_values(by=['Grupo', 'Plaza', 'Tiempo'])\n",
        "\n",
        "# Apply thematic classification (for both Moderators and Participants)\n",
        "cleaned_df = cleaned_df.groupby(['Grupo', 'Plaza'], group_keys=False).apply(classify_thematic_categories)\n",
        "\n",
        "# Apply propagation classification (only for Moderators)\n",
        "cleaned_df = cleaned_df.groupby(['Grupo', 'Plaza'], group_keys=False).apply(classify_propagation)\n",
        "\n",
        "# Propagate propagation themes from Moderators to both Moderators and Participants\n",
        "cleaned_df = cleaned_df.groupby(['Grupo', 'Plaza'], group_keys=False).apply(propagate_moderator_themes)\n",
        "\n",
        "# Save the results to a new CSV file\n",
        "output_path = \"Base de datos final.csv\"\n",
        "cleaned_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"Multi-thematic classification with updated rules completed, saved to '{output_path}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK0t73-K8JSg",
        "outputId": "a55ca7dc-ffa8-4929-82f6-91f5bf035539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-37-4291347196.py:92: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  cleaned_df = cleaned_df.groupby(['Grupo', 'Plaza'], group_keys=False).apply(classify_thematic_categories)\n",
            "/tmp/ipython-input-37-4291347196.py:95: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  cleaned_df = cleaned_df.groupby(['Grupo', 'Plaza'], group_keys=False).apply(classify_propagation)\n",
            "/tmp/ipython-input-37-4291347196.py:98: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  cleaned_df = cleaned_df.groupby(['Grupo', 'Plaza'], group_keys=False).apply(propagate_moderator_themes)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-thematic classification with updated rules completed, saved to 'Base de datos final.csv'.\n"
          ]
        }
      ]
    }
  ]
}